{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model creation playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 169659 words by Jerry in the all Seinfeld episodes!\n",
      "\n",
      "Few words by Jerry:\n",
      "['do', 'you', 'know', 'what', 'this', 'is', 'all', 'about', 'eos', 'do', 'you', 'know', 'why', 'were', 'here', 'eos', 'to', 'be', 'out', 'this', 'is', 'out', 'and', 'out', 'is', 'one', 'of', 'the', 'single', 'most', 'enjoyable', 'experiences', 'of', 'life', 'eos', 'people', 'did', 'you', 'ever', 'hear', 'people', 'talking', 'about', 'we', 'should', 'go', 'out', 'eos', 'this', 'is']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os import path\n",
    "import string\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# We will just use dialogue by Jerry\n",
    "input_file_path = path.join(\"..\", \"input_files\", \"complete_seinfeld_scripts.csv\")\n",
    "\n",
    "EOS = \"eos\"\n",
    "words_by_jerry = []\n",
    "with open(input_file_path) as input_file:\n",
    "    input_data = csv.DictReader(input_file)\n",
    "    for row in input_data:\n",
    "        if(row['Character'] == 'JERRY'):\n",
    "            for words in row['Dialogue'].split():\n",
    "                for word in word_tokenize(words):\n",
    "                    word = word.replace(\"...\", \"\")\n",
    "                    word = word.replace(\".\", EOS)\n",
    "                    word = word.replace(\"?\", EOS)\n",
    "                    word = word.replace(\"!\", EOS)\n",
    "                    if word.isalpha():\n",
    "                        words_by_jerry.append(word.lower())\n",
    "print(\"There are {} words by Jerry in the all Seinfeld episodes!\\n\".format(len(words_by_jerry)))\n",
    "print(\"Few words by Jerry:\")\n",
    "print(words_by_jerry[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 most common words by jerry are:\n",
      "[('eos', 23097), ('you', 6212), ('i', 6204), ('the', 5097), ('a', 3435), ('to', 3407), ('it', 3127), ('that', 2298), ('what', 2188), ('do', 1967), ('and', 1576), ('of', 1574), ('is', 1536), ('in', 1500), ('he', 1318), ('this', 1268), ('know', 1240), ('no', 1165), ('on', 1162), ('me', 1087)]\n",
      "20 least common words by jerry are:\n",
      "[('flinching', 1), ('theoseosthat', 1), ('fornicator', 1), ('mohair', 1), ('verge', 1), ('kom', 1), ('repack', 1), ('problemseoseos', 1), ('unhealthy', 1), ('dumped', 1), ('slough', 1), ('immature', 1), ('dente', 1), ('reston', 1), ('schnapps', 1), ('perks', 1), ('lampshades', 1), ('henry', 1), ('site', 1), ('welcoming', 1)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "n_most_common = 20\n",
    "counter = collections.Counter(words_by_jerry)\n",
    "print(\"{} most common words by jerry are:\\n{}\".format(n_most_common, counter.most_common(n_most_common)))\n",
    "print(\"{} least common words by jerry are:\\n{}\".format(n_most_common, counter.most_common()[:-n_most_common-1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is: 9254.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Create a tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# And build the word index\n",
    "tokenizer.fit_on_texts(words_by_jerry)\n",
    "\n",
    "# This is how we can recover the word index that was computed\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Vocabulary size\n",
    "vocabulary_size = len(word_index) + 1\n",
    "print(\"Vocabulary size is: {}.\".format(vocabulary_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squences size is: 169659.\n"
     ]
    }
   ],
   "source": [
    "# This turns strings into lists of integer indices.\n",
    "text_sequences = tokenizer.texts_to_sequences(words_by_jerry)\n",
    "\n",
    "sequences = []\n",
    "for sequence in text_sequences:\n",
    "    for seq in sequence:\n",
    "        sequences.append(seq)\n",
    "print(\"Squences size is: {}.\".format(len(sequences)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing prefix and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 169652 prefixes and 169652 targets, respectively.\n"
     ]
    }
   ],
   "source": [
    "# Get sequence of max_len words\n",
    "max_len = 7\n",
    "\n",
    "# Lists to hold the prefixes and targets\n",
    "prefix_sequences = []\n",
    "target_character = []\n",
    "for i in range (len(sequences) - max_len):\n",
    "    prefix_sequences.append(sequences[i: i + max_len])\n",
    "    target_character.append(sequences[i + max_len])\n",
    "print(\"There are {} prefixes and {} targets, respectively.\".format(len(prefix_sequences), \n",
    "                                                                   len(target_character)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(169652, 7)\n",
      "(169652, 9254)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "X = np.array(prefix_sequences)\n",
    "\n",
    "# normalize\n",
    "X = X / float(vocabulary_size)\n",
    "\n",
    "y = to_categorical(target_character, num_classes=vocabulary_size)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Options are 50, 100, 200, 300\n",
    "embedding_dim = 200\n",
    "\n",
    "glove_dir = 'glove.6B'\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(path.join(\"..\", glove_dir, 'glove.6B.{}d.txt'.format(embedding_dim)))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < vocabulary_size:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and validation sets (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 135721 samples.\n",
      "The validation set has 33931 samples.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=99)\n",
    "\n",
    "print(\"The training set has %d samples.\" % len(X_train))\n",
    "print(\"The validation set has %d samples.\" % len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7, 200)            1850800   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 200)            320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9254)              1860054   \n",
      "=================================================================\n",
      "Total params: 4,392,654\n",
      "Trainable params: 4,392,654\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dropout\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(Embedding(vocabulary_size, embedding_dim, input_length=max_len))\n",
    "model.add(LSTM(embedding_dim, dropout=0.25, recurrent_dropout=0.25, return_sequences=True))\n",
    "model.add(LSTM(embedding_dim, dropout=0.25, recurrent_dropout=0.25))\n",
    "model.add(Dense(embedding_dim, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7, 200)            1850800   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 200)            320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9254)              1860054   \n",
      "=================================================================\n",
      "Total params: 4,392,654\n",
      "Trainable params: 2,541,854\n",
      "Non-trainable params: 1,850,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].set_weights([embedding_matrix])\n",
    "model.layers[0].trainable = False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr=1E-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135721 samples, validate on 33931 samples\n",
      "Epoch 1/20\n",
      "135721/135721 [==============================] - 138s 1ms/step - loss: 8.6073 - val_loss: 8.1701\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 8.17007, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 2/20\n",
      "135721/135721 [==============================] - 136s 1ms/step - loss: 7.7829 - val_loss: 7.4590\n",
      "\n",
      "Epoch 00002: val_loss improved from 8.17007 to 7.45900, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 3/20\n",
      "135721/135721 [==============================] - 137s 1ms/step - loss: 7.1197 - val_loss: 6.8758\n",
      "\n",
      "Epoch 00003: val_loss improved from 7.45900 to 6.87582, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 4/20\n",
      "135721/135721 [==============================] - 136s 1000us/step - loss: 6.5980 - val_loss: 6.4431\n",
      "\n",
      "Epoch 00004: val_loss improved from 6.87582 to 6.44310, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 5/20\n",
      "135721/135721 [==============================] - 137s 1ms/step - loss: 6.2345 - val_loss: 6.1680\n",
      "\n",
      "Epoch 00005: val_loss improved from 6.44310 to 6.16800, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 6/20\n",
      "135721/135721 [==============================] - 136s 1ms/step - loss: 6.0189 - val_loss: 6.0242\n",
      "\n",
      "Epoch 00006: val_loss improved from 6.16800 to 6.02423, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 7/20\n",
      "135721/135721 [==============================] - 137s 1ms/step - loss: 5.9127 - val_loss: 5.9663\n",
      "\n",
      "Epoch 00007: val_loss improved from 6.02423 to 5.96629, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 8/20\n",
      "135721/135721 [==============================] - 143s 1ms/step - loss: 5.8673 - val_loss: 5.9475\n",
      "\n",
      "Epoch 00008: val_loss improved from 5.96629 to 5.94747, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 9/20\n",
      "135721/135721 [==============================] - 138s 1ms/step - loss: 5.8455 - val_loss: 5.9423\n",
      "\n",
      "Epoch 00009: val_loss improved from 5.94747 to 5.94229, saving model to ../saved_models/model_weights.hdf5\n",
      "Epoch 10/20\n",
      "135721/135721 [==============================] - 141s 1ms/step - loss: 5.8323 - val_loss: 5.9432\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 5.94229\n",
      "Epoch 11/20\n",
      "135721/135721 [==============================] - 138s 1ms/step - loss: 5.8235 - val_loss: 5.9476\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 5.94229\n",
      "Epoch 12/20\n",
      "135721/135721 [==============================] - 139s 1ms/step - loss: 5.8173 - val_loss: 5.9542\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 5.94229\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "Epoch 13/20\n",
      "135721/135721 [==============================] - 139s 1ms/step - loss: 5.8128 - val_loss: 5.9570\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 5.94229\n",
      "Epoch 14/20\n",
      "135721/135721 [==============================] - 139s 1ms/step - loss: 5.8116 - val_loss: 5.9606\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 5.94229\n",
      "Epoch 15/20\n",
      "135721/135721 [==============================] - 138s 1ms/step - loss: 5.8105 - val_loss: 5.9647\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 5.94229\n",
      "Epoch 16/20\n",
      "135721/135721 [==============================] - 136s 1ms/step - loss: 5.8094 - val_loss: 5.9690\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 5.94229\n",
      "Epoch 17/20\n",
      "135721/135721 [==============================] - 134s 990us/step - loss: 5.8085 - val_loss: 5.9732\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 5.94229\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "Epoch 18/20\n",
      "135721/135721 [==============================] - 140s 1ms/step - loss: 5.8075 - val_loss: 5.9745\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 5.94229\n",
      "Epoch 19/20\n",
      "135721/135721 [==============================] - 137s 1ms/step - loss: 5.8072 - val_loss: 5.9759\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 5.94229\n",
      "Epoch 20/20\n",
      "135721/135721 [==============================] - 138s 1ms/step - loss: 5.8070 - val_loss: 5.9772\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 5.94229\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "\n",
    "# Stop training when a monitored quantity has stopped improving after 20 epochs\n",
    "early_stop = EarlyStopping(patience=20, verbose=1)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.3, patience=3, cooldown=3, verbose=1)\n",
    "\n",
    "# Save the best model after every epoch\n",
    "check_point = ModelCheckpoint(filepath='../saved_models/model_weights.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "                             validation_data=(X_val, y_val), \n",
    "                             callbacks=[check_point, early_stop, reduce_lr])\n",
    "\n",
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training', 'Validation'], loc='upper left')\n",
    "plt.savefig('../plots/model_loss.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the real time auto-complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test text: Do you know what\n",
      "Do you know what not what in who ran i what purification spent you worst brings woman my damn blender tonight better i gums just fishing do have you rolodex youve mate the bad im yes up there you versa and you i someone out incinerator one smuckers no thought danny eos he the\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "test_text = \"Do you know what\"\n",
    "\n",
    "print('Test text:', test_text)\n",
    "temperature = 1.2\n",
    "\n",
    "outputs = [test_text]\n",
    "for _ in range(50):\n",
    "    clean_text = []\n",
    "    for word in word_tokenize(test_text):\n",
    "        if word.isalpha():\n",
    "            clean_text.append(word)\n",
    "    text_sequences = tokenizer.texts_to_sequences(clean_text)\n",
    "    sequences = []\n",
    "    for sequence in text_sequences:\n",
    "        for seq in sequence:\n",
    "            sequences.append(seq)\n",
    "    \n",
    "    # Truncate sequences to a fixed length\n",
    "    test_text_encoded = pad_sequences([sequences], maxlen=max_len, truncating='pre')\n",
    "    preds = model.predict(test_text_encoded, verbose=0)[0]\n",
    "    yhat = sample(preds, temperature)\n",
    "        \n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    for word, index in word_index.items():\n",
    "        if index == yhat:\n",
    "            out_word = word\n",
    "            break\n",
    "            \n",
    "    #if out_word == EOS:\n",
    "        #break\n",
    "        \n",
    "    outputs.append(out_word)\n",
    "    test_text += \" \" + out_word\n",
    "            \n",
    "print(\" \".join(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envAutoCompleteJerry",
   "language": "python",
   "name": "envautocompletejerry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
