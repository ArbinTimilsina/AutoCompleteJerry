{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "from pickle import load\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "model_and_weights = os.path.join(\"../\", \"saved_models\", \"model_and_weights.hdf5\")\n",
    "model = load_model(model_and_weights)\n",
    "\n",
    "for_server = load(open('../saved_models/for_server.pkl', 'rb'))\n",
    "tokenizer, word_index, sequence_max_len = for_server[0], for_server[1], for_server[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test text: What is the deal with\n",
      "What is the deal with crashed fumble health kicking forces gail thin normally design corked soda matters dad hookup 12 affectionate dondi pregnant sendrax towing fiftysixth uromycitisis released which issue fuckbleepeding jill indistinct aids deny badmouthed source era sr. service interference emergency ruler lunches loan hangin payment industrious think discount limitations overlook bucks to sorts.\n"
     ]
    }
   ],
   "source": [
    "test_text = \"What is the deal with\"\n",
    "\n",
    "punctuations_filter='!\"#$%&\\'()*+,-/:;<=>@[\\\\]^_`{|}~'\n",
    "\n",
    "def remove_punctuations(sentence):\n",
    "    return sentence.translate(str.maketrans('', '', punctuations_filter))\n",
    "\n",
    "def remove_dots(sentence):\n",
    "    return sentence.replace('...', ' ')\n",
    "\n",
    "def remove_nonascii(word):\n",
    "    return ''.join([char if ord(char) < 128 else '' for char in word])\n",
    "\n",
    "def make_lower(word):\n",
    "    return word.lower()\n",
    "\n",
    "def clean_word(word):\n",
    "    processed = remove_nonascii(word)\n",
    "    processed = make_lower(processed)\n",
    "    return processed\n",
    "\n",
    "print('Test text:', test_text)\n",
    "temperature = 1.3\n",
    "\n",
    "outputs = [test_text]\n",
    "for _ in range(50):\n",
    "    test_text = remove_punctuations(test_text)\n",
    "    clean_text = []\n",
    "    for word in word_tokenize(test_text):\n",
    "        clean_text.append(clean_word(word))\n",
    "        \n",
    "    text_sequences = tokenizer.texts_to_sequences(clean_text)\n",
    "    text_padded = pad_sequences(text_sequences, maxlen=sequence_max_len, truncating='pre')\n",
    "\n",
    "    preds = model.predict(text_padded, verbose=0)[0]\n",
    "    yhat = sample(preds, temperature)\n",
    "    \n",
    "    # map predicted word index to word\n",
    "    out_word = ''\n",
    "    EOS = \".?\"\n",
    "    for word, index in word_index.items():\n",
    "        if index == yhat:\n",
    "            out_word = word\n",
    "            break\n",
    "        \n",
    "    if out_word in EOS:\n",
    "        break\n",
    "                \n",
    "    outputs.append(out_word)\n",
    "    test_text += \" \" + out_word\n",
    "    \n",
    "outputs = \" \".join(outputs)\n",
    "outputs += \".\"\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the deal with crashed fumble health kicking forces gail thin normally design corked soda matters dad hookup 12 affectionate dondi pregnant sendrax towing fiftysixth uromycitisis released which issue fuckbleepeding jill indistinct aids deny badmouthed source era sr. service interference emergency ruler lunches loan hangin payment industrious think discount limitations overlook bucks to sorts.\n"
     ]
    }
   ],
   "source": [
    "import spacy, re\n",
    "\n",
    "def improve_output(text):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    doc = nlp(text)\n",
    "\n",
    "    #Tag: The detailed part-of-speech tag. NN: common noun, NNS: plural, NNP: proper noun\n",
    "    tagged_sentence = [(w.text, w.tag_) for w in doc]\n",
    "    normalized_sent = [w.capitalize() if t in [\"NNP\", \"NNPS\"] else w for (w, t) in tagged_sentence]\n",
    "    normalized_sent[0] = normalized_sent[0].capitalize()\n",
    "    return re.sub(\" (?=[\\.,'!?:;])\", \"\", ' '.join(normalized_sent))\n",
    "\n",
    "print(improve_output(outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envAutoCompleteJerry",
   "language": "python",
   "name": "envautocompletejerry"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
